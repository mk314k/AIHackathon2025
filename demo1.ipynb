{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_ids = {\n",
    "    'guoyww_v2': \"guoyww/animatediff-motion-adapter-v1-5-2\", # original motion adapter\n",
    "    'guoyww_v3': \"guoyww/animatediff-motion-adapter-v1-5-3\",\n",
    "    'guoyww_sdxl': \"guoyww/animatediff-motion-adapter-sdxl-beta\",\n",
    "    'wangfuyun': \"wangfuyun/AnimateLCM\",\n",
    "}\n",
    "model_ids = {\n",
    "    'frankjoshua': \"frankjoshua/toonyou_beta6\",\n",
    "    'SG161222': \"SG161222/Realistic_Vision_V5.1_noVAE\",\n",
    "    'emilianJR': \"emilianJR/epiCRealism\",\n",
    "    'stabilityai': \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "}\n",
    "controlnet_ids = {\n",
    "    'lllyasviel': \"lllyasviel/control_v11f1p_sd15_depth\",\n",
    "    'guoyww_scr': \"guoyww/animatediff-sparsectrl-scribble\",\n",
    "    'guoyww_rgb': \"guoyww/animatediff-sparsectrl-rgb\",\n",
    "}\n",
    "vae_ids = {\n",
    "    'stabilityai': \"stabilityai/sd-vae-ft-mse\",\n",
    "}\n",
    "lora_adapter_ids = {\n",
    "    'guoyww': \"guoyww/animatediff-motion-lora-v1-5-3\",\n",
    "    'wangfuyun': \"wangfuyun/AnimateLCM\",\n",
    "    }\n",
    "depth_detector_ids = {\n",
    "    'lllyasviel': \"lllyasviel/Annotators\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f3d063a04642c9a5985b5d48562e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from diffusers import AnimateDiffPipeline, LCMScheduler, MotionAdapter, AutoencoderKL\n",
    "import torch\n",
    "from diffusers.utils import export_to_gif, load_image, load_video, export_to_video\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6a26a94fe64d1da329b7f2a42b79c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1837c0cfeb484581b4a88ff10142fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb28979dde9941f5ab046575a00b6935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49eb1e20f6b74bdda0fcd88b67d79e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337877cb5ff248beb8ed53fd007ced27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2530fccc4e54c72964af25fab8dccdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774d06a1fa9645c8aa77e607cea8dc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eeb7e24e6b48e5bd8e734904f35c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/374 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e652f429c60e4b81b14d1da94bbd9450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/config.json:   0%|          | 0.00/697 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8001d19c17b49bd859c56c924366fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13a2208742c4eceb02c369598840930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)ature_extractor/preprocessor_config.json:   0%|          | 0.00/520 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5709b0db534a6c9df3b77eeed5c48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fba371d12b04154bb548871480f3afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af3056747ba49c0b36c17742bc60b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8bf019aa563411680e283af5dff47d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/565 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe1f96046c34f62acf6cbcf08fec304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef708d11eb3a4498982ce61ed20d4c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a50f7f72ee14cde9d34cc5226c87b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dd009c3f19463db19ac3a00deff200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/rhassanzadeh1/anaconda3/envs/GenAI/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "An error occurred while trying to fetch /home/users/rhassanzadeh1/.cache/huggingface/hub/models--frankjoshua--toonyou_beta6/snapshots/9bb5e1c5be60ab664ec80bff429126e0844ac9fe/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /home/users/rhassanzadeh1/.cache/huggingface/hub/models--frankjoshua--toonyou_beta6/snapshots/9bb5e1c5be60ab664ec80bff429126e0844ac9fe/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227252f4149046eba5c371b2ba607e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AnimateLCM_sd15_t2v_lora.safetensors:   0%|          | 0.00/135M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc714d282cf7481794aa331ccb20796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (111 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['the neon store sign flickers, casting an eerie glow onto the cracked pavement, with a lonely parking lot and distant traffic in the background, cinematic night - time atmosphere.', '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', '<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbb80fcc19b429e946a2915a9cae7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "motion_adapter = MotionAdapter.from_pretrained(\"wangfuyun/AnimateLCM\", torch_dtype=dtype)\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\", torch_dtype=dtype)\n",
    "\n",
    "model_id = \"frankjoshua/toonyou_beta6\" # frankjoshua/toonyou_beta6, emilianJR/epiCRealism, SG161222/Realistic_Vision_V5.1_noVAE\n",
    "pipe = AnimateDiffPipeline.from_pretrained(model_id, motion_adapter=motion_adapter, vae=vae, torch_dtype=dtype)\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config, beta_schedule=\"linear\", torch_dtype=dtype)\n",
    "\n",
    "pipe.load_lora_weights(\n",
    "    lora_adapter_ids['wangfuyun'], weight_name=\"AnimateLCM_sd15_t2v_lora.safetensors\", adapter_name=\"lcm-lora\",\n",
    "    )\n",
    "pipe.load_lora_weights(lora_adapter_ids['guoyww'], adapter_name=\"motion_lora\") # more lora adapter at https://huggingface.co/guoyww\n",
    "pipe.set_adapters(\"lcm-lora\", [0.8])\n",
    "# pipe.set_adapters([\"lcm-lora\", \"motion_lora\"], adapter_weights=[0.8, 1.0])\n",
    "\n",
    "# Enable FreeNoise for long prompt generation\n",
    "pipe.enable_free_noise(context_length=16, context_stride=4)\n",
    "pipe.to(device)\n",
    "# Save memory\n",
    "pipe.enable_free_noise_split_inference()\n",
    "pipe.unet.enable_forward_chunking()\n",
    "\n",
    "# Can be a single prompt, or a dictionary with frame timesteps\n",
    "i=100\n",
    "prompt = {\n",
    "    0: \"\"\"\n",
    "    Cartoon style portrait of a 34-year-old white man with a scruffy brown beard, messy hair, and tired eyes, walking out of 'PickWick Mini Mart' at night. Heâ€™s wearing a wrinkled blue uniform polo with a worn-out name tag, slouched shoulders, and carrying an energy drink can, looking exhausted and fed up. The neon store sign flickers, casting an eerie glow onto the cracked pavement, with a lonely parking lot and distant traffic in the background, cinematic night-time atmosphere.\"\"\",\n",
    "    i*1: \"\"\"\n",
    "    Inside a messy apartment with fast food wrappers, empty energy drink cans, and BMX magazines scattered on a stained couch, the same scruffy man sits slouched, watching an X-Games documentary on an old TV, eyes wide with excitement, imagining himself as a pro BMX rider, dim lighting from a single lamp casting long shadows.\n",
    "    \"\"\",\n",
    "    i*2: \"\"\"\n",
    "    Above his head, a vivid daydream of himself as 'Benny the Bullet,' wearing a neon-green Monster Energy-branded BMX suit, soaring through the air in a dramatic mid-air stunt with flashing cameras and cheering crowds, bright, exaggerated cartoon-style visuals with bold motion lines.\n",
    "    \"\"\",\n",
    "    i*3: \"\"\"\n",
    "    A Reddit thread glowing on his laptop screen, with a bold post reading â€˜Money is just energyâ€”GO GET IT,â€™ the man's eyes lighting up with a sudden burst of motivation, exaggerated cartoon-like glow around his face, a mix of ambition and delusion.\n",
    "    \"\"\",\n",
    "    i*4: \"\"\"\n",
    "    Benny standing proudly outside a large bank, wearing sunglasses and a scarf, with a confident smirk, imagining himself casually walking inside to claim his fortune, vibrant and humorous composition with a slightly exaggerated comic book effect.\n",
    "    \"\"\",\n",
    "}\n",
    "negative_prompt = \"bad quality, worst quality, jpeg artifacts\"\n",
    "\n",
    "# Run inference\n",
    "output = pipe(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative_prompt,\n",
    "    num_frames=i*5,\n",
    "    guidance_scale=2.5,\n",
    "    num_inference_steps=10,\n",
    "    generator=torch.Generator('cpu').manual_seed(42),\n",
    ")\n",
    "\n",
    "# Save video\n",
    "frames = output.frames[0]\n",
    "export_to_video(frames, \"outputs/output1.mp4\", fps=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "genai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
